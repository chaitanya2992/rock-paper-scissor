{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.7337345480918884</th>\n",
       "      <th>0.9035224914550781</th>\n",
       "      <th>1.2042000729906022e-09</th>\n",
       "      <th>0.6250970363616943</th>\n",
       "      <th>0.8761696815490723</th>\n",
       "      <th>-0.04391536861658096</th>\n",
       "      <th>0.5531324148178101</th>\n",
       "      <th>0.7691171169281006</th>\n",
       "      <th>-0.06877519935369492</th>\n",
       "      <th>0.5242459177970886</th>\n",
       "      <th>...</th>\n",
       "      <th>0.8865261077880859</th>\n",
       "      <th>0.4904824197292328</th>\n",
       "      <th>-0.10170750319957733</th>\n",
       "      <th>0.9027105569839478</th>\n",
       "      <th>0.3989044725894928</th>\n",
       "      <th>-0.1327393651008606</th>\n",
       "      <th>0.9143387079238892</th>\n",
       "      <th>0.3204108476638794</th>\n",
       "      <th>-0.15807373821735382</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757106</td>\n",
       "      <td>0.945450</td>\n",
       "      <td>-5.933828e-09</td>\n",
       "      <td>0.634720</td>\n",
       "      <td>0.908448</td>\n",
       "      <td>-0.053947</td>\n",
       "      <td>0.552473</td>\n",
       "      <td>0.790677</td>\n",
       "      <td>-0.081167</td>\n",
       "      <td>0.525295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885959</td>\n",
       "      <td>0.486416</td>\n",
       "      <td>-0.101645</td>\n",
       "      <td>0.900784</td>\n",
       "      <td>0.397809</td>\n",
       "      <td>-0.134667</td>\n",
       "      <td>0.912126</td>\n",
       "      <td>0.315002</td>\n",
       "      <td>-0.160758</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.763426</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>-9.761228e-09</td>\n",
       "      <td>0.651359</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>-0.052453</td>\n",
       "      <td>0.573327</td>\n",
       "      <td>0.775963</td>\n",
       "      <td>-0.088760</td>\n",
       "      <td>0.545956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913531</td>\n",
       "      <td>0.487273</td>\n",
       "      <td>-0.154836</td>\n",
       "      <td>0.927691</td>\n",
       "      <td>0.397010</td>\n",
       "      <td>-0.187151</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>-0.212572</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763347</td>\n",
       "      <td>0.981806</td>\n",
       "      <td>-8.003544e-09</td>\n",
       "      <td>0.646985</td>\n",
       "      <td>0.910450</td>\n",
       "      <td>-0.041125</td>\n",
       "      <td>0.571474</td>\n",
       "      <td>0.777250</td>\n",
       "      <td>-0.073274</td>\n",
       "      <td>0.546699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912343</td>\n",
       "      <td>0.496702</td>\n",
       "      <td>-0.161910</td>\n",
       "      <td>0.928762</td>\n",
       "      <td>0.403933</td>\n",
       "      <td>-0.195926</td>\n",
       "      <td>0.941111</td>\n",
       "      <td>0.314480</td>\n",
       "      <td>-0.223578</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.799150</td>\n",
       "      <td>0.980805</td>\n",
       "      <td>-6.069633e-09</td>\n",
       "      <td>0.671528</td>\n",
       "      <td>0.912606</td>\n",
       "      <td>-0.062142</td>\n",
       "      <td>0.591012</td>\n",
       "      <td>0.775953</td>\n",
       "      <td>-0.094802</td>\n",
       "      <td>0.564295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933763</td>\n",
       "      <td>0.481884</td>\n",
       "      <td>-0.102916</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>0.395128</td>\n",
       "      <td>-0.136227</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.312986</td>\n",
       "      <td>-0.162925</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.781919</td>\n",
       "      <td>0.988184</td>\n",
       "      <td>-6.101822e-09</td>\n",
       "      <td>0.658334</td>\n",
       "      <td>0.914371</td>\n",
       "      <td>-0.053372</td>\n",
       "      <td>0.578898</td>\n",
       "      <td>0.780408</td>\n",
       "      <td>-0.087696</td>\n",
       "      <td>0.553548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928182</td>\n",
       "      <td>0.495870</td>\n",
       "      <td>-0.142108</td>\n",
       "      <td>0.944194</td>\n",
       "      <td>0.406480</td>\n",
       "      <td>-0.178273</td>\n",
       "      <td>0.954461</td>\n",
       "      <td>0.316826</td>\n",
       "      <td>-0.207201</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.841633</td>\n",
       "      <td>-8.710984e-09</td>\n",
       "      <td>0.714238</td>\n",
       "      <td>0.753550</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.649220</td>\n",
       "      <td>0.680612</td>\n",
       "      <td>-0.059201</td>\n",
       "      <td>0.592746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678207</td>\n",
       "      <td>0.811446</td>\n",
       "      <td>-0.288175</td>\n",
       "      <td>0.672572</td>\n",
       "      <td>0.838285</td>\n",
       "      <td>-0.265786</td>\n",
       "      <td>0.701564</td>\n",
       "      <td>0.834606</td>\n",
       "      <td>-0.251422</td>\n",
       "      <td>scissor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.839379</td>\n",
       "      <td>-8.376031e-09</td>\n",
       "      <td>0.702226</td>\n",
       "      <td>0.756762</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.636414</td>\n",
       "      <td>0.679751</td>\n",
       "      <td>-0.055902</td>\n",
       "      <td>0.575739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670008</td>\n",
       "      <td>0.785508</td>\n",
       "      <td>-0.272790</td>\n",
       "      <td>0.665549</td>\n",
       "      <td>0.818720</td>\n",
       "      <td>-0.255024</td>\n",
       "      <td>0.690475</td>\n",
       "      <td>0.818157</td>\n",
       "      <td>-0.243620</td>\n",
       "      <td>scissor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>0.797549</td>\n",
       "      <td>0.845746</td>\n",
       "      <td>-9.869330e-09</td>\n",
       "      <td>0.707293</td>\n",
       "      <td>0.763719</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>0.644384</td>\n",
       "      <td>0.691257</td>\n",
       "      <td>-0.060397</td>\n",
       "      <td>0.588794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677730</td>\n",
       "      <td>0.813663</td>\n",
       "      <td>-0.267091</td>\n",
       "      <td>0.676183</td>\n",
       "      <td>0.845907</td>\n",
       "      <td>-0.248489</td>\n",
       "      <td>0.708310</td>\n",
       "      <td>0.837409</td>\n",
       "      <td>-0.237083</td>\n",
       "      <td>scissor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>0.801674</td>\n",
       "      <td>0.841527</td>\n",
       "      <td>-1.123604e-08</td>\n",
       "      <td>0.712680</td>\n",
       "      <td>0.748866</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.645301</td>\n",
       "      <td>0.671123</td>\n",
       "      <td>-0.062565</td>\n",
       "      <td>0.578083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673494</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>-0.285487</td>\n",
       "      <td>0.676700</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>-0.256976</td>\n",
       "      <td>0.714011</td>\n",
       "      <td>0.839016</td>\n",
       "      <td>-0.237999</td>\n",
       "      <td>scissor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>0.799917</td>\n",
       "      <td>0.846679</td>\n",
       "      <td>-9.823759e-09</td>\n",
       "      <td>0.707880</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>0.673609</td>\n",
       "      <td>-0.054785</td>\n",
       "      <td>0.579895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671261</td>\n",
       "      <td>0.812955</td>\n",
       "      <td>-0.282703</td>\n",
       "      <td>0.676696</td>\n",
       "      <td>0.842381</td>\n",
       "      <td>-0.259253</td>\n",
       "      <td>0.712043</td>\n",
       "      <td>0.835797</td>\n",
       "      <td>-0.243321</td>\n",
       "      <td>scissor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.7337345480918884   0.9035224914550781   1.2042000729906022e-09  \\\n",
       "0               0.757106             0.945450            -5.933828e-09   \n",
       "1               0.763426             0.968200            -9.761228e-09   \n",
       "2               0.763347             0.981806            -8.003544e-09   \n",
       "3               0.799150             0.980805            -6.069633e-09   \n",
       "4               0.781919             0.988184            -6.101822e-09   \n",
       "...                  ...                  ...                      ...   \n",
       "1500            0.808906             0.841633            -8.710984e-09   \n",
       "1501            0.791434             0.839379            -8.376031e-09   \n",
       "1502            0.797549             0.845746            -9.869330e-09   \n",
       "1503            0.801674             0.841527            -1.123604e-08   \n",
       "1504            0.799917             0.846679            -9.823759e-09   \n",
       "\n",
       "       0.6250970363616943   0.8761696815490723   -0.04391536861658096  \\\n",
       "0                0.634720             0.908448              -0.053947   \n",
       "1                0.651359             0.904321              -0.052453   \n",
       "2                0.646985             0.910450              -0.041125   \n",
       "3                0.671528             0.912606              -0.062142   \n",
       "4                0.658334             0.914371              -0.053372   \n",
       "...                   ...                  ...                    ...   \n",
       "1500             0.714238             0.753550               0.000513   \n",
       "1501             0.702226             0.756762               0.000393   \n",
       "1502             0.707293             0.763719              -0.004032   \n",
       "1503             0.712680             0.748866              -0.000963   \n",
       "1504             0.707880             0.754663               0.003026   \n",
       "\n",
       "       0.5531324148178101   0.7691171169281006   -0.06877519935369492  \\\n",
       "0                0.552473             0.790677              -0.081167   \n",
       "1                0.573327             0.775963              -0.088760   \n",
       "2                0.571474             0.777250              -0.073274   \n",
       "3                0.591012             0.775953              -0.094802   \n",
       "4                0.578898             0.780408              -0.087696   \n",
       "...                   ...                  ...                    ...   \n",
       "1500             0.649220             0.680612              -0.059201   \n",
       "1501             0.636414             0.679751              -0.055902   \n",
       "1502             0.644384             0.691257              -0.060397   \n",
       "1503             0.645301             0.671123              -0.062565   \n",
       "1504             0.641482             0.673609              -0.054785   \n",
       "\n",
       "       0.5242459177970886  ...   0.8865261077880859   0.4904824197292328  \\\n",
       "0                0.525295  ...             0.885959             0.486416   \n",
       "1                0.545956  ...             0.913531             0.487273   \n",
       "2                0.546699  ...             0.912343             0.496702   \n",
       "3                0.564295  ...             0.933763             0.481884   \n",
       "4                0.553548  ...             0.928182             0.495870   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "1500             0.592746  ...             0.678207             0.811446   \n",
       "1501             0.575739  ...             0.670008             0.785508   \n",
       "1502             0.588794  ...             0.677730             0.813663   \n",
       "1503             0.578083  ...             0.673494             0.816322   \n",
       "1504             0.579895  ...             0.671261             0.812955   \n",
       "\n",
       "       -0.10170750319957733   0.9027105569839478   0.3989044725894928  \\\n",
       "0                 -0.101645             0.900784             0.397809   \n",
       "1                 -0.154836             0.927691             0.397010   \n",
       "2                 -0.161910             0.928762             0.403933   \n",
       "3                 -0.102916             0.952639             0.395128   \n",
       "4                 -0.142108             0.944194             0.406480   \n",
       "...                     ...                  ...                  ...   \n",
       "1500              -0.288175             0.672572             0.838285   \n",
       "1501              -0.272790             0.665549             0.818720   \n",
       "1502              -0.267091             0.676183             0.845907   \n",
       "1503              -0.285487             0.676700             0.843879   \n",
       "1504              -0.282703             0.676696             0.842381   \n",
       "\n",
       "       -0.1327393651008606   0.9143387079238892   0.3204108476638794  \\\n",
       "0                -0.134667             0.912126             0.315002   \n",
       "1                -0.187151             0.938095             0.313165   \n",
       "2                -0.195926             0.941111             0.314480   \n",
       "3                -0.136227             0.969423             0.312986   \n",
       "4                -0.178273             0.954461             0.316826   \n",
       "...                    ...                  ...                  ...   \n",
       "1500             -0.265786             0.701564             0.834606   \n",
       "1501             -0.255024             0.690475             0.818157   \n",
       "1502             -0.248489             0.708310             0.837409   \n",
       "1503             -0.256976             0.714011             0.839016   \n",
       "1504             -0.259253             0.712043             0.835797   \n",
       "\n",
       "       -0.15807373821735382    paper  \n",
       "0                 -0.160758    paper  \n",
       "1                 -0.212572    paper  \n",
       "2                 -0.223578    paper  \n",
       "3                 -0.162925    paper  \n",
       "4                 -0.207201    paper  \n",
       "...                     ...      ...  \n",
       "1500              -0.251422  scissor  \n",
       "1501              -0.243620  scissor  \n",
       "1502              -0.237083  scissor  \n",
       "1503              -0.237999  scissor  \n",
       "1504              -0.243321  scissor  \n",
       "\n",
       "[1505 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv('dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.57105649e-01,  9.45449591e-01, -5.93382810e-09, ...,\n",
       "         9.12125587e-01,  3.15001756e-01, -1.60758495e-01],\n",
       "       [ 7.63426006e-01,  9.68199909e-01, -9.76122827e-09, ...,\n",
       "         9.38094735e-01,  3.13164949e-01, -2.12572381e-01],\n",
       "       [ 7.63347030e-01,  9.81805801e-01, -8.00354361e-09, ...,\n",
       "         9.41111326e-01,  3.14479887e-01, -2.23578036e-01],\n",
       "       ...,\n",
       "       [ 7.97548532e-01,  8.45745921e-01, -9.86933024e-09, ...,\n",
       "         7.08309710e-01,  8.37409377e-01, -2.37082765e-01],\n",
       "       [ 8.01673770e-01,  8.41526687e-01, -1.12360370e-08, ...,\n",
       "         7.14011192e-01,  8.39015663e-01, -2.37998769e-01],\n",
       "       [ 7.99917161e-01,  8.46678793e-01, -9.82375870e-09, ...,\n",
       "         7.12042928e-01,  8.35796833e-01, -2.43320644e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset.iloc[:,:-1].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['paper', 'paper', 'paper', ..., 'scissor', 'scissor', 'scissor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1204, 63)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1204,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 63)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vanam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier1=LogisticRegression()\n",
    "classifier1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier2=KNeighborsClassifier()\n",
    "classifier2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier3=DecisionTreeClassifier()\n",
    "classifier3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier4=RandomForestClassifier()\n",
    "classifier4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966777408637874\n",
      "1.0\n",
      "0.9966777408637874\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred1=classifier1.predict(x_test)\n",
    "y_pred2=classifier2.predict(x_test)\n",
    "y_pred3=classifier3.predict(x_test)\n",
    "y_pred4=classifier4.predict(x_test)\n",
    "print(accuracy_score(y_pred1,y_test))\n",
    "print(accuracy_score(y_pred2,y_test))\n",
    "print(accuracy_score(y_pred3,y_test))\n",
    "print(accuracy_score(y_pred4,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model=open('model.pk1','wb')\n",
    "pickle.dump(classifier1,model)\n",
    "model.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
